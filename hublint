#!/usr/bin/env python3

import argparse
import collections
import json
import sys
import textwrap
import time
import tomllib

import jsonschema
import requests
import yaml

RED = ''
GREEN = ''
YELLOW = ''
BLUE = ''
RESET = ''
UNDERLINE = ''

BOL = '\r'
ERASETOEOL = '\033[0K'

# TODO:
# de-duplicate code for warning, error (reduce cyclo)
# tests
# MarkDown output
# publish comment on PR


isatty = sys.stdout.isatty


def init_colors(force):
    global RED, GREEN, YELLOW, BLUE, RESET, UNDERLINE
    if force == 'always' or (force == 'auto' and isatty()):
        RED = '\033[91m'
        GREEN = '\033[92m'
        YELLOW = '\033[93m'
        BLUE = '\033[94m'
        RESET = '\033[0m'
        UNDERLINE = '\033[4m'


# from https://github.com/yaml/pyyaml/issues/456
class TrackingLoader(yaml.SafeLoader):
    def __init__(self, stream):
        super().__init__(stream)
        self.locations = {}

    def compose_node(self, parent, index):
        # Get the start position before composing the node
        start_line, start_column = self.line, self.column
        node = super().compose_node(parent, index)
        # Attach the start position to the node itself
        node._myloader_start_location = (start_line, start_column)
        return node

    def construct_object(self, node, deep=False):
        # Construct the object first
        obj = super().construct_object(node, deep=deep)
        key = id(obj)
        # Use the start location attached to the node
        if hasattr(node, '_myloader_start_location'):
            self.locations[key] = node._myloader_start_location
        else:
            self.locations[key] = None
        return obj

    @classmethod
    def load(cls, stream):
        loader = cls(stream)
        try:
            return loader.get_single_data(), loader.locations
        finally:
            loader.dispose()


class Index:
    def __init__(self, content):
        # self._index = json.loads(content)
        self._index, self._yaml_locations = TrackingLoader.load(content)
        self.hubtypes = list(self._index.keys())

    def __iter__(self):
        for hubtype, content in self._index.items():
            for key, spec in content.items():
                yield Item(hubtype, key, spec)

    def get_location(self, ob):
        return self._yaml_locations.get(id(ob))


class Item:
    def __init__(self, hubtype, key, spec):
        self.hubtype = hubtype
        self.key = key
        self._spec = spec
        self._warnings = collections.defaultdict(list)
        self._errors = collections.defaultdict(list)

    def __str__(self):
        return f"{self.hubtype}:{self.key}"

    def validate(self, index, linters):
        if isatty():
            # fake delay to show the cute spinner
            time.sleep(0.005)
        for linter in linters:
            fails = list(linter(self, index))
            if not fails:
                continue
            if linter.error:
                self._errors[linter.name].extend(fails)
            else:
                self._warnings[linter.name].extend(fails)

    def yaml_content(self):
        try:
            pth = self._spec['path']
        except KeyError:
            return ""
        try:
            with open(pth) as file:
                return file.read()
        except FileNotFoundError:
            return ""

    # XXX: loading documents can have errors, how to handle them?
    def yaml_docs(self):
        content = self.yaml_content()
        if not content:
            return
        for doc in yaml.safe_load_all(content):
            yield doc

    def data_urls(self):
        for doc in self.yaml_docs():
            data = doc.get("data", [])
            for data in data:
                if 'source_url' in data:
                    yield data['source_url']


class Linter:
    def __init__(self):
        cls = self.__class__.__name__
        if not hasattr(self, "name"):
            raise ValueError(f"Linter {cls} must have a name")
        if not hasattr(self, "description"):
            raise ValueError(f"Linter {cls} must have a description")
        if not hasattr(self, "enabled"):
            raise ValueError(f"Linter {cls} must have a default 'enabled' attribute")
        if not hasattr(self, "error"):
            raise ValueError(f"Linter {cls} must have a default 'error' attribute")
        if not hasattr(self, "__call__"):
            raise ValueError(f"Linter {cls} must have a __call__ method")


# yeah, it's a joke/example
class NotLinux(Linter):
    name = "not-linux"
    description = "Item name must not contain 'linux'"
    enabled = False
    error = False

    def __call__(self, item, index):
        if 'linux' in item.key:
            yield f"Name contains 'linux': {item.key}", index._index[item.hubtype][item.key]


class OnlyCollectionHaveDependencies(Linter):
    name = "only-collection-have-dependencies"
    description = "Only collections can have dependencies"
    enabled = True
    error = True

    def __call__(self, item, index):
        if item.hubtype == "collections":
            return
        for typ in index.hubtypes:
            deps = item._spec.get(typ, [])
            if deps:
                yield f"Item declares dependencies but it's not a collection: {typ}={deps}.", index._index[item.hubtype][item.key][typ]


class EmptyDependencies(Linter):
    name = "empty-dependencies"
    description = "An item (collection) contains an explicit empty dependency (ex. parsers=[])"
    enabled = True
    error = False

    def __call__(self, item, index):
        for typ in index.hubtypes:
            if item._spec.get(typ) == []:
                yield f"Empty dependency: {typ}=[]", index._index[item.hubtype][item.key][typ]


class OneDocumentPerYAMLFile(Linter):
    name = "one-document-per-yaml-file"
    description = "Each YAML file must contain only one document"
    enabled = True
    error = False

    def __call__(self, item, index):
        names = [doc.get("name") for doc in item.yaml_docs()]
        if len(names) > 1:
            yield f"File {item._spec['path']} contains more than one document: {names}", None


class MissingAuthor(Linter):
    name = "missing-author"
    description = "Each item must have an author field"
    enabled = True
    error = True

    def __call__(self, item, index):
        if not item._spec.get("author"):
            yield "Missing 'author' field", index._index[item.hubtype][item.key]


class MissingItemFile(Linter):
    name = "missing-item-file"
    description = "The item file is missing"
    enabled = True
    error = True

    def __call__(self, item, index):
        try:
            with open(item._spec['path']):
                pass
        except FileNotFoundError:
            yield f"File '{item._spec['path']}' does not exist"
        except KeyError:
            yield "Missing 'path' field", index._index[item.hubtype][item.key]


class MissingDependencies(Linter):
    name = "missing-dependencies"
    description = "An item declares a dependency that does not exist"
    enabled = True
    error = True

    def __call__(self, item, index):
        for typ in index.hubtypes:
            for dep_idx, dep in enumerate(item._spec.get(typ, [])):
                if dep not in index._index.get(typ, {}):
                    yield f"Dependency '{typ}:{dep}' does not exist", index._index[item.hubtype][item.key][typ][dep_idx]


class BadPath(Linter):
    name = "bad-path"
    description = "The path must match the item type, stage (if it exists) and name"
    enabled = True
    error = False

    def __call__(self, item, index):
        stage = item._spec.get("stage")
        basedir = f"{item.hubtype}/{stage}" if stage else item.hubtype
        expected_paths = [
            f"{basedir}/{item.key}.yml",
            f"{basedir}/{item.key}.yaml",
        ]
        pth = item._spec.get("path")
        if pth not in expected_paths:
            ob = index._index[item.hubtype][item.key]
            if 'path' in ob:
                ob = ob['path']
            yield f"Path '{pth}' does not match the item type, stage and name (must be one of: {expected_paths})", ob


class MissingPath(Linter):
    name = "missing-path"
    description = "Each item must have a path field"
    enabled = True
    error = True

    def __call__(self, item, index):
        if not item._spec.get("path"):
            yield "Missing 'path' field", index._index[item.hubtype][item.key]


class AuthorMatchkey(Linter):
    name = "author-match-key"
    description = "The author field must match the item key"
    enabled = True
    error = True

    def __call__(self, item, index):
        author = item._spec.get("author", "")
        if not item.key.startswith(author + '/'):
            ob = index._index[item.hubtype][item.key]
            if 'author' in ob:
                ob = ob['author']
            yield f"Author field '{author}' does not match the item key '{item.key}'", ob


class DocumentWithoutName(Linter):
    name = "document-without-name"
    description = "Each section of a YAML file must have a name (only scenarios)"
    enabled = True
    error = True
    # XXX: we could make linters configurable from the toml file
    config = {'hubtypes': ['scenarios']}

    def __call__(self, item, index):
        if item.hubtype not in self.config['hubtypes']:
            return
        for doc in item.yaml_docs():
            if not doc.get("name"):
                yield f"YAML document without name: {item._spec['path']}", None


class DocumentNameMatchingItem(Linter):
    name = "document-name-matching-item"
    description = "The name of the document must match the item name (only scenarios)"
    enabled = True
    error = True
    config = {'hubtypes': ['scenarios']}

    def __call__(self, item, index):
        if item.hubtype not in self.config['hubtypes']:
            return
        for doc in item.yaml_docs():
            if doc.get("name") == item.key:
                return
        yield f"YAML file {item._spec.get('path')} does not have a document named: {item.key}", None


class ItemSchema(Linter):
    name = "item-schema"
    description = "Validate item files against their YAML schema"
    enabled = True
    error = True
    config = {
        'collections': {
            'url': 'https://raw.githubusercontent.com/crowdsecurity/crowdsec-yaml-schemas/main/collection_schema.yaml',
        },
        'parsers': {
            'url': 'https://raw.githubusercontent.com/crowdsecurity/crowdsec-yaml-schemas/main/parser_schema.yaml',
        },
        'scenarios': {
            'url': 'https://raw.githubusercontent.com/crowdsecurity/crowdsec-yaml-schemas/main/scenario_schema.yaml',
        },
        'postoverflows': {
            'url': 'https://raw.githubusercontent.com/crowdsecurity/crowdsec-yaml-schemas/main/parser_schema.yaml',
        },
    }

    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self._schemas = {}

    def __call__(self, item, index):
        if item.hubtype not in self.config:
            return

        if item.hubtype not in self._schemas:
            try:
                yaml_schema = requests.get(self.config[item.hubtype]['url']).text
                self._schemas[item.hubtype] = yaml.safe_load(yaml_schema)
            except requests.RequestException as e:
                yield f"Failed to fetch schema for {item.hubtype}: {e}", None
                return

        schema = self._schemas[item.hubtype]
        for doc in item.yaml_docs():
            try:
                jsonschema.validate(doc, schema)
            except jsonschema.ValidationError as e:
                yield f"File {item._spec.get('path')} does not match the schema: {e.message}", None


class DataFilesExist(Linter):
    name = "data-files-exist"
    description = "Check the source_url of the data files declared in the item"
    enabled = False
    error = True

    def __call__(self, item, index):
        for url in item.data_urls():
            try:
                if isatty():
                    print(f"Fetching {url}{ERASETOEOL}{BOL}", end="")
                requests.head(url).raise_for_status()
            except requests.RequestException as e:
                yield f"Failed to fetch data file {url}: {e}", None


# --------------------------------------------------------------------- #

# validate configuration and create linters
def linters_from_config(config):
    cfg_linters = config.get("linters", {})
    # create a default configuration for all linters
    for linter_class in Linter.__subclasses__():
        # see if the class can be instantiated, or defaults are missing
        linter_class()
        if linter_class.name not in cfg_linters:
            cfg_linters[linter_class.name] = {}

    for linter_name, linter_cfg in cfg_linters.items():
        for linter_class in Linter.__subclasses__():
            # TODO: check for duplicates
            if linter_class.name == linter_name:
                linter = linter_class()
                if linter_cfg.get("enabled") is not None:
                    linter.enabled = linter_cfg.get("enabled")
                if linter_cfg.get("error") is not None:
                    linter.error = linter_cfg.get("error")
                yield linter
                break
        else:
            raise ValueError(f"Unknown linter: {linter_name}")


def run_linters(index_file, enabled_linters, no_warnings=False, show_location=False):
    # leave feedback for successful checks too
    print_ok = False

    try:
        content = index_file.read()
        index = Index(content)
    except json.JSONDecodeError as e:
        print(f"Error parsing JSON: {e}", file=sys.stderr)
        sys.exit(1)

    spinner = [
        "▹▹▹▹▹",
        "▸▹▹▹▹",
        "▹▸▹▹▹",
        "▹▹▸▹▹",
        "▹▹▹▸▹",
        "▹▹▹▹▸"
    ]

    all_items = list(index)
    tot = len(all_items)

    tot_warnings = 0
    tot_errors = 0

    errors_by_linter = collections.defaultdict(int)
    warnings_by_linter = collections.defaultdict(int)

    for idx, item in enumerate(all_items):
        check = spinner[idx % len(spinner)]

        if isatty():
            print(f" {check} [{idx}/{tot}] {item}{BOL}", end="")

        item.validate(index, enabled_linters)

        print_feedback = False

        if item._errors:
            check = RED + '✗' + RESET
            print_feedback = True
        elif item._warnings:
            check = YELLOW + '⚠' + RESET
            print_feedback = True
        else:
            check = GREEN + '✓' + RESET
            if not isatty():
                print_feedback = False

        if print_feedback or print_ok:
            print(f" {check} {item}{ERASETOEOL}", end="\n" if print_ok else f"{BOL}")

        if item._errors or item._warnings:
            if print_feedback or print_ok:
                print("")
            for lintername, errors in sorted(item._errors.items()):
                for error in errors:
                    tot_errors += 1
                    errors_by_linter[lintername] += 1
                    file = index_file.name
                    if error[1] and show_location:
                        location = index.get_location(error[1])
                        if location:
                            location = f" {file}:{location[0]+1}:{location[1]+1}:"
                        else:
                            location = ""
                    else:
                        location = ""
                    print(f"{RED}{lintername}:{RESET}{location} {error[0]}")
            for lintername, warnings in sorted(item._warnings.items()):
                for warning in warnings:
                    tot_warnings += 1
                    warnings_by_linter[lintername] += 1
                    if no_warnings:
                        continue
                    file = index_file.name
                    if warning[1] and show_location:
                        location = index.get_location(warning[1])
                        if location:
                            location = f" {file}:{location[0]+1}:{location[1]+1}:"
                        else:
                            location = ""
                    else:
                        location = ""
                    print(f"{YELLOW}{lintername}:{RESET}{location} {warning[0]}")

    print()
    print(f"Checked {tot} items: {tot_warnings} warnings, {tot_errors} errors")
    print()
    print("Errors by linter:")
    for linter, count in sorted(errors_by_linter.items()):
        print(f" {linter}: {count}")

    print("Warnings by linter:")
    for linter, count in sorted(warnings_by_linter.items()):
        print(f" {linter}: {count}")

    return tot_errors


def read_config(config_file=None):
    try:
        return tomllib.load(config_file)
    except tomllib.TOMLDecodeError as e:
        print(f"Error parsing TOML: {e}", file=sys.stderr)
        sys.exit(1)


def print_linters(linters):
    print("Available linters:")
    for linter in linters:
        enabled = f"{GREEN}✓{RESET}" if linter.enabled else f"{RED}✗{RESET}"
        print(f" {enabled} {linter.name}: {linter.description}")
        if linter.enabled:
            if linter.error:
                print("   error")
            else:
                print("   warning")


def add_config_argument(parser):
    parser.add_argument('--config', default='.hublint.toml', type=argparse.FileType('rb'),
                        help='The configuration file')


def print_default_config():
    linters = list(Linter.__subclasses__())
    for linter in linters:
        print(f'# {linter.description}')
        print(f"[linters.{linter.name}]")
        print(f"enabled = {linter.enabled.__str__().lower()}")
        print(f"error = {linter.error.__str__().lower()}")
        print("")


def main(argv):
    parser = argparse.ArgumentParser(description='Validate hub index files',
                                     formatter_class=argparse.RawTextHelpFormatter,
                                     epilog=textwrap.dedent("""
                                     Example:

                                     # generate the initial configuration
                                     hublint defaults > .hublint.toml

                                     # validate an index file
                                     hublint check --index .index.json
                                     """))

    subparsers = parser.add_subparsers(dest='command')

    parser_linters = subparsers.add_parser('linters', help='Show all the available linters')
    add_config_argument(parser_linters)

    parser_check = subparsers.add_parser('check', help='Validate an index file')
    parser_check.add_argument('--index', default='.index.json', type=argparse.FileType(),
                              help='The index file to validate')
    parser_check.add_argument('--color', choices=['always', 'never', 'auto'], default='auto',
                              help='Force colored output')
    parser_check.add_argument('--no-warning-details', action='store_true',
                              help='Do not show warning details (still, count them)')
    parser_check.add_argument('--show-location', action='store_true',
                              help='Show the location of the error/warning')
    # XXX: --debug option, for logger and to keep stack trace on CTRL+C

    add_config_argument(parser_check)

    subparsers.add_parser('defaults', help='Show the default configuration',
                          epilog=textwrap.dedent("""
                          Example:

                          #generate an initial configuration file
                          hublint defaults > .hublint.toml
                          """))

    args = parser.parse_args()

    if args.command not in [None, 'defaults']:
        print(f"Using config: {args.config.name}")
        config = read_config(args.config)
        all_linters = list(linters_from_config(config))

    if args.command == "linters":
        print_linters(all_linters)
        sys.exit(0)
    elif args.command == "check":
        init_colors(args.color)
        print(f"Validating: '{args.index.name}'")
        print()
        tot_errors = run_linters(args.index, [linter for linter in all_linters if linter.enabled],
                                 no_warnings=args.no_warning_details,
                                 show_location=args.show_location)
        sys.exit(tot_errors > 0)
    elif args.command == "defaults":
        print_default_config()
        sys.exit(0)
    else:
        parser.print_help()
        sys.exit(1)


if __name__ == "__main__":
    try:
        main(sys.argv)
    except KeyboardInterrupt:
        sys.exit(1)
